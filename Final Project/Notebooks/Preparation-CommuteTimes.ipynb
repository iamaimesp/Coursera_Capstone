{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the next line to install the `requests` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries:\n",
    "* `requests`, for making HTTP GET requests\n",
    "* `pandas`, for importing CSV files into a dataframe, and viceversa\n",
    "* `json_normalize`, for parsing the JSON response from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd \n",
    "from pandas.io.json import json_normalize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the Bing API Key in a variable so we can append it to the HTTP requests easily.\n",
    "\n",
    "Please, update the next cell with your own Bing API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we will save in variables the coordinates of the commute destination, and the different commute start times that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination=\"38.8548783, -77.0517428\"\n",
    "startTimes=[\"06:00:00\", \"06:30:00\", \"07:00:00\", \"07:30:00\", \"08:00:00\", \"08:30:00\", \"09:00:00\", \"09:30:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the dataframe where we will store the commute times, providing the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_pd = pd.DataFrame(columns=[\"ZCTA5CE10\", \"06:00:00\", \"06:30:00\", \"07:00:00\", \"07:30:00\", \"08:00:00\", \"08:30:00\", \"09:00:00\", \"09:30:00\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the contents of the CSV file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations=pd.read_csv(\"prepared_data/zcta_md_dc_va.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we get to the main loop of this notebook. The process here is to iterate over the dataframe read from the CSV file (`locations`), reading the ZCTA value and the coordinates for the internal point. For each of these entries, we use for loops to get the combinations of 'commute start time' and 'commute day' (going from March 2nd 2020 (Monday) to March 6th (Friday) for a full week), and for each of these combinations, we build the HTTP request in the variable `url`, send the request, and process the result to obtain the returned commute time. This time we accumulate in the variable `acumCommuteTime` and after iterating over the 5 days of the week, we compute the average (that is, the average of the commute starting at a given time, for the 5 days of the week). This average value (stored in the variable `finalTime`) is pushed into the dataframe of commute times (`commute_pd`). \n",
    "\n",
    "After the lengthy process of making all these queries, the dataframe will be fully populated. We show the top and bottom rows for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in locations.index:\n",
    "    rowdata = {\"ZCTA5CE10\" : str(locations[\"ZCTA5CE10\"][i])}\n",
    "    for st in startTimes:\n",
    "        acumCommuteTime=0\n",
    "        for day in range (2,7):\n",
    "            url=\"https://dev.virtualearth.net/REST/v1/Routes/DistanceMatrix?origins=\" + str(locations[\"INTPTLAT10\"][i]) + \",\" + str(locations[\"INTPTLON10\"][i]) + \"&destinations=\" + destination + \"&travelMode=driving&startTime=2020-03-0\" + str(day) + \"T\" + st + \"-05:00&key=\" + apikey\n",
    "            results = requests.get(url).json()\n",
    "            acumCommuteTime += results['resourceSets'][0]['resources'][0]['results'][0]['travelDuration'];\n",
    "        \n",
    "        finalTime = acumCommuteTime / 5\n",
    "        \n",
    "        rowdata.update({st : finalTime})\n",
    "    commute_pd = commute_pd.append (rowdata, ignore_index=True)\n",
    "commute_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save the dataframe to the CSV file `zcta_commute_times.csv` in the `prepared_data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_pd.to_csv('prepared_data/zcta_commute_times.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
